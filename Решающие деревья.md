–û—Ç–ª–∏—á–Ω–æ! –î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º **—Ä–µ—à–∞—é—â–∏–µ –¥–µ—Ä–µ–≤—å—è (Decision Trees)** ‚Äî –æ–¥–Ω—É –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏.  

### **1. –ß—Ç–æ —Ç–∞–∫–æ–µ —Ä–µ—à–∞—é—â–µ–µ –¥–µ—Ä–µ–≤–æ?**  
–†–µ—à–∞—é—â–µ–µ –¥–µ—Ä–µ–≤–æ ‚Äî —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º **–æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º**, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏** –∏ **—Ä–µ–≥—Ä–µ—Å—Å–∏–∏**. –û–Ω —Å—Ç—Ä–æ–∏—Ç **–∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É** (–¥–µ—Ä–µ–≤–æ), –≥–¥–µ:  
- **–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —É–∑–ª—ã** ‚Äî –ø—Ä–∏–∑–Ω–∞–∫–∏ (—É—Å–ª–æ–≤–∏—è).  
- **–í–µ—Ç–≤–∏** ‚Äî –≤–æ–∑–º–æ–∂–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.  
- **–õ–∏—Å—Ç—å—è** ‚Äî –∫–æ–Ω–µ—á–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è (–∫–ª–∞—Å—Å—ã –∏–ª–∏ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è).  

üìå **–ü—Ä–∏–º–µ—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**  
```
–ï—Å–ª–∏ (–ü–æ–≥–æ–¥–∞ = –°–æ–ª–Ω–µ—á–Ω–æ) –∏ (–í–ª–∞–∂–Ω–æ—Å—Ç—å ‚â§ 70%) ‚Üí "–ò–≥—Ä–∞—Ç—å –≤ —Ç–µ–Ω–Ω–∏—Å"
–ò–Ω–∞—á–µ ‚Üí "–ù–µ –∏–≥—Ä–∞—Ç—å"
```

### **2. –ö–∞–∫ —Å—Ç—Ä–æ–∏—Ç—Å—è –¥–µ—Ä–µ–≤–æ?**  
–î–µ—Ä–µ–≤–æ —Å—Ç—Ä–æ–∏—Ç—Å—è **–∂–∞–¥–Ω–æ**, –≤—ã–±–∏—Ä–∞—è –ª—É—á—à–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.  

#### **–ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**  
1. **–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**  
   - **–≠–Ω—Ç—Ä–æ–ø–∏—è (Entropy)** ‚Äì –º–µ—Ä–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏.  
	
	$H(S) = -\sum_{i} p_i \log_2 p_i$
    
   - **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –≤—ã–∏–≥—Ä—ã—à (Information Gain, IG)** ‚Äì —É–º–µ–Ω—å—à–µ–Ω–∏–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏ –ø–æ—Å–ª–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è.  
    
     $IG(S, A) = H(S) - \sum_{v \in A} \frac{|S_v|}{|S|} H(S_v)$
    
   - **–ò–Ω–¥–µ–∫—Å –î–∂–∏–Ω–∏ (Gini Impurity)** ‚Äì –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—à–∏–±–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.  
     
     $Gini(S) = 1 - \sum_{i} p_i^2$
    

2. **–î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:**  
   - **–î–∏—Å–ø–µ—Ä—Å–∏—è (Variance)** ‚Äì –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è MSE (Mean Squared Error).  

#### **–ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è:**  
1. –í—ã–±—Ä–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫ —Å **–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º IG** (–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å—é).  
2. –†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ —ç—Ç–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É.  
3. –ü–æ–≤—Ç–æ—Ä—è—Ç—å —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ, –ø–æ–∫–∞:  
   - –í—Å–µ –æ–±—ä–µ–∫—Ç—ã –≤ –ª–∏—Å—Ç–µ –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞.  
   - –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞.  
   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ ‚â§ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞.  

### **3. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**  
‚úÖ **–ü–ª—é—Å—ã:**  
- –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ (–º–æ–∂–Ω–æ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å).  
- –†–∞–±–æ—Ç–∞–µ—Ç —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.  
- –ù–µ —Ç—Ä–µ–±—É–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.  

‚ùå **–ú–∏–Ω—É—Å—ã:**  
- **–°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é** (–æ—Å–æ–±–µ–Ω–Ω–æ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –≥–ª—É–±–∏–Ω—ã).  
- –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ —à—É–º–∞–º –∏ –≤—ã–±—Ä–æ—Å–∞–º.  
- –ñ–∞–¥–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º ‚Üí –º–æ–∂–µ—Ç –Ω–µ –Ω–∞–π—Ç–∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–π –æ–ø—Ç–∏–º—É–º.  

### **4. –ë–æ—Ä—å–±–∞ —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º**  
- **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã (max_depth).**  
- **–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è (min_samples_split).**  
- **–ü—Ä—É–Ω–∏–Ω–≥ (Post-pruning)** ‚Äì —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –≤–µ—Ç–≤–µ–π –ø–æ—Å–ª–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è.  

### **5. –í–∞—Ä–∏–∞—Ü–∏–∏ –∏ —É–ª—É—á—à–µ–Ω–∏—è**  
- **–°–ª—É—á–∞–π–Ω—ã–µ –ª–µ—Å–∞ (Random Forest)** ‚Äì –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –º–Ω–æ–≥–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤.  
- **–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ (XGBoost, LightGBM, CatBoost)** ‚Äì –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.  

### **6. –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ (Scikit-learn)**  
```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data = load_iris()
X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = DecisionTreeClassifier(max_depth=3, criterion="gini")
model.fit(X_train, y_train)

# –û—Ü–µ–Ω–∫–∞
print("Accuracy:", model.score(X_test, y_test))
```

### **–í—ã–≤–æ–¥**  
–†–µ—à–∞—é—â–∏–µ –¥–µ—Ä–µ–≤—å—è ‚Äî –º–æ—â–Ω—ã–π –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –Ω–æ –≤–∞–∂–Ω–æ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –∏—Ö —Å–ª–æ–∂–Ω–æ—Å—Ç—å. –î–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏ (Random Forest, Gradient Boosting).  

üîπ **–ù–∞ —ç–∫–∑–∞–º–µ–Ω–µ –º–æ–≥—É—Ç —Å–ø—Ä–æ—Å–∏—Ç—å:**  
- –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç IG/Gini?  
- –ü–æ—á–µ–º—É –¥–µ—Ä–µ–≤—å—è —Å–∫–ª–æ–Ω–Ω—ã –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é?  
- –ß–µ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –¥–µ—Ä–µ–≤–æ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏?  


[[!–í–æ–ø—Ä–æ—Å—ã –∫ —ç–∫–∑–∞–º–µ–Ω—É]]