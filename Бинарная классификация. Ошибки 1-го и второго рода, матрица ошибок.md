### **Бинарная классификация: ошибки 1-го и 2-го рода, матрица ошибок**  

Бинарная классификация — это задача машинного обучения, где модель предсказывает один из двух возможных классов (например: "спам" / "не спам", "болен" / "здоров").  

#### **1. Матрица ошибок (Confusion Matrix)**  
Матрица ошибок — это таблица, которая показывает, сколько раз модель правильно и неправильно предсказала классы.  

Для бинарной классификации матрица выглядит так:  

|                     | **Фактический класс: 1 (Positive)** | **Фактический класс: 0 (Negative)** |
|---------------------|------------------------------------|------------------------------------|
| **Предсказанный класс: 1 (Positive)** | True Positive (TP)                | False Positive (FP)                |
| **Предсказанный класс: 0 (Negative)** | False Negative (FN)               | True Negative (TN)                |

- **True Positive (TP)** — модель верно предсказала положительный класс.  
- **False Positive (FP)** — модель ошибочно предсказала положительный класс (ошибка 1-го рода).  
- **False Negative (FN)** — модель ошибочно предсказала отрицательный класс (ошибка 2-го рода).  
- **True Negative (TN)** — модель верно предсказала отрицательный класс.  

#### **2. Ошибки 1-го и 2-го рода**  

- **Ошибка 1-го рода (False Positive, FP, "Ложная тревога")**  
  - Модель предсказывает класс "1", хотя на самом деле "0".  
  - **Пример:** Спам-фильтр пометил важное письмо как спам.  

- **Ошибка 2-го рода (False Negative, FN, "Пропуск цели")**  
  - Модель предсказывает класс "0", хотя на самом деле "1".  
  - **Пример:** Врач не диагностировал болезнь у пациента, который болен.  

#### **3. Метрики качества классификации**  
На основе матрицы ошибок можно вычислить важные метрики:  

1. **Accuracy (Точность)**  

   $\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$
   
   Доля правильных предсказаний.  

3. **Precision (Точность предсказания положительного класса)**  $\text{Precision} = \frac{TP}{TP + FP}$
   
4. Показывает, сколько из предсказанных "1" действительно "1".  

5. **Recall (Полнота, Sensitivity, True Positive Rate)**  
   $\text{Recall} = \frac{TP}{TP + FN}$

   Показывает, сколько реальных "1" модель правильно нашла.  

6. **F1-Score (Гармоническое среднее Precision и Recall)**  
   $F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$

   Учитывает и точность, и полноту.  

7. **Specificity (True Negative Rate)**  
   $\text{Specificity} = \frac{TN}{TN + FP}$

   Показывает, сколько реальных "0" модель правильно нашла.  

#### **4. Когда важнее минимизировать FP или FN?**  
- **Если FP критично (ошибка 1-го рода хуже):**  
  - Пример: Суд признаёт невиновного виновным.  
  - Нужно повышать **Precision**.  

- **Если FN критично (ошибка 2-го рода хуже):**  
  - Пример: Врач пропустил болезнь.  
  - Нужно повышать **Recall**.  

#### **5. Пример расчёта**  
Допустим, есть модель, которая предсказывает, болен ли пациент:  

|                     | **Фактически болен (1)** | **Фактически здоров (0)** |
|---------------------|-------------------------|--------------------------|
| **Предсказано "болен" (1)** | TP = 80                | FP = 10                  |
| **Предсказано "здоров" (0)** | FN = 20                | TN = 90                  |

- **Accuracy** = (80 + 90) / (80 + 90 + 10 + 20) = 170 / 200 = 0.85 (85%)  
- **Precision** = 80 / (80 + 10) = 80 / 90 ≈ 0.89 (89%)  
- **Recall** = 80 / (80 + 20) = 80 / 100 = 0.8 (80%)  
- **F1-Score** = 2 × (0.89 × 0.8) / (0.89 + 0.8) ≈ 0.84  

#### **Вывод**  
- Матрица ошибок помогает анализировать качество модели.  
- Ошибки 1-го рода (FP) и 2-го рода (FN) имеют разную важность в зависимости от задачи.  
- Выбор метрики (Precision, Recall, F1) зависит от того, какие ошибки критичны.  